<div class='block' >

    <h2>2015</h2>
    
        <div class='paperblock' >
        <table>
	  
        <td width=150px>
	  
        
        </td>
        <td style='vertical-align:middle'>
        
 	      <span class=bibtitle>
          Neural Activation Constellations: Unsupervised Part Model Discovery with Convolutional Networks.</span>
          <br />
          <span class=bibauthor>Marcel Simon and Erik Rodner.</span>
          <br />
          <span class=bibvenue>International Conference on Computer Vision (ICCV).</span>
          
          <span class=bibyear>2015.</span>
        
		
		
	
        <a href="http://hera.inf-cv.uni-jena.de:6680/bib/Simon15:NAC" onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img src="bibworldfiles/get-bib-source.png" alt="BibTeX" /></a>
        
        
        <a href="http://arxiv.org/abs/1504.08289"><img src="bibworldfiles/web-link.png" alt="www" title="www" target="_blank"/></a>
        
        
        
        
        
        <span class="abstractlink" onClick="abstractclick('Simon15:NAC');">more ...</span>
        <div class="bibabstract" id="Simon15:NAC">
          <br />
          <div class='vspace'></div>
          Abstract: Part models of object categories are essential for challenging recognition tasks, where differences in categories are subtle and only reflected in appearances of small parts of the object. We present an approach that is able to learn part models in a completely unsupervised manner, without part annotations and even without given bounding boxes during learning. The key idea is to find constellations of neural activation patterns computed using convolutional neural networks. In our experiments, we outperform existing approaches for fine-grained recognition on the CUB200-2011, Oxford PETS, and Oxford Flowers dataset in case no part or bounding box annotations are available and achieve state-of-the-art performance for the Stanford Dog dataset. We also show the benefits of neural constellation models as a data augmentation technique for fine-tuning. Furthermore, our paper unites the areas of generic and fine-grained classification, since our approach is suitable for both scenarios.
          
        </div>
        </td>
        </table>
        </div>
        <div class='vspace'></div>
    
        <div class='paperblock' >
        <table>
	  
        <td width=150px>
	  
        
          
                <img width=90% class=teaserimg src="http://hera.inf-cv.uni-jena.de:6680/teaser/Simon15:FCI">
          
        
        </td>
        <td style='vertical-align:middle'>
        
 	      <span class=bibtitle>
          Fine-grained Classification of Identity Document Types with Only One Example.</span>
          <br />
          <span class=bibauthor>Marcel Simon and Erik Rodner and Joachim Denzler.</span>
          <br />
          <span class=bibvenue>Machine Vision Applications (MVA).</span>
          
          <span class=bibpages>126 - 129.</span>
          
          <span class=bibyear>2015.</span>
        
		
		
	
        <a href="http://hera.inf-cv.uni-jena.de:6680/bib/Simon15:FCI" onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img src="bibworldfiles/get-bib-source.png" alt="BibTeX" /></a>
        
        
        <a href="http://www.mva-org.jp/mva2015/FinalProgram_20150423_clean.pdf"><img src="bibworldfiles/web-link.png" alt="www" title="www" target="_blank"/></a>
        
        
        
        
        
        <span class="abstractlink" onClick="abstractclick('Simon15:FCI');">more ...</span>
        <div class="bibabstract" id="Simon15:FCI">
          <br />
          <div class='vspace'></div>
          Abstract: This paper shows how to recognize types of identity documents, such as passports, using state-of-the-art visual recognition approaches. Whereas recognizing individual parts on identity documents with a standardized layout is one of the old classics in computer vision, recognizing the type of the document and therefore also the layout is a challenging problem due to the large variation of the documents.  In our paper, we evaluate different techniques for this application including feature representations based on recent achievements with convolutional neural networks.
          
        </div>
        </td>
        </table>
        </div>
        <div class='vspace'></div>
    
        <div class='paperblock' >
        <table>
	  
        <td width=150px>
	  
        
          
                <img width=90% class=teaserimg src="http://hera.inf-cv.uni-jena.de:6680/teaser/Rodner15:FRD">
          
        
        </td>
        <td style='vertical-align:middle'>
        
 	      <span class=bibtitle>
          <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Rodner15:FRD.pdf">Fine-grained Recognition Datasets for Biodiversity Analysis</a>.</span>
          <br />
          <span class=bibauthor>Erik Rodner and Marcel Simon and Gunnar Brehm and Stephanie Pietsch and J. Wolfgang WÃ¤gele and Joachim Denzler.</span>
          <br />
          <span class=bibvenue>CVPR Workshop on Fine-grained Visual Classification (CVPR-WS).</span>
          
          <span class=bibyear>2015.</span>
        
		
		
	
        <a href="http://hera.inf-cv.uni-jena.de:6680/bib/Rodner15:FRD" onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img src="bibworldfiles/get-bib-source.png" alt="BibTeX" /></a>
        
        <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Rodner15:FRD.pdf"><img src="bibworldfiles/pdf-document.png" alt="pdf" title="pdf"/></a>
        
        
        <a href="http://www.inf-cv.uni-jena.de/fgvcbiodiv"><img src="bibworldfiles/web-link.png" alt="www" title="www" target="_blank"/></a>
        
        
        
        
        
        </div>
        </td>
        </table>
        </div>
        <div class='vspace'></div>
    

    <h2>2014</h2>
    
        <div class='paperblock' >
        <table>
	  
        <td width=150px>
	  
        
          
                <img width=90% class=teaserimg src="http://hera.inf-cv.uni-jena.de:6680/teaser/Freytag14:ESP">
          
        
        </td>
        <td style='vertical-align:middle'>
        
 	      <span class=bibtitle>
          <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Freytag14:ESP.pdf">Exemplar-specific Patch Features for Fine-grained Recognition</a>.</span>
          <br />
          <span class=bibauthor>Alexander Freytag and Erik Rodner and Trevor Darrell and Joachim  Denzler.</span>
          <br />
          <span class=bibvenue>German Conference on Pattern Recognition (GCPR).</span>
          
          <span class=bibpages>144-156.</span>
          
          <span class=bibyear>2014.</span>
        
		
		
	
        <a href="http://hera.inf-cv.uni-jena.de:6680/bib/Freytag14:ESP" onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img src="bibworldfiles/get-bib-source.png" alt="BibTeX" /></a>
        
        <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Freytag14:ESP.pdf"><img src="bibworldfiles/pdf-document.png" alt="pdf" title="pdf"/></a>
        
        
        
        <a href="https://github.com/cvjena/patchDiscovery"><img src="bibworldfiles/code-link.png" alt="code" title="code" target="_blank"/></a>
        
        
        
        <a href="http://hera.inf-cv.uni-jena.de:6680/supplementary/.pdf"><img src="bibworldfiles/supplementary.png" alt="supplementary" title="supplementary" target="_blank"/></a>
        
        
        <span class="abstractlink" onClick="abstractclick('Freytag14:ESP');">more ...</span>
        <div class="bibabstract" id="Freytag14:ESP">
          <br />
          <div class='vspace'></div>
          Abstract: In this paper, we present a new approach for fine-grained recognition or subordinate categorization,  tasks where an algorithm needs to reliably differentiate between visually similar categories, e.g. different bird species.  While previous approaches aim at learning a single generic representation and models with increasing complexity,  we propose an orthogonal approach that learns patch representations specifically tailored to every single test exemplar.  Since we query a constant number of images similar to a given test image,  we obtain very compact features and avoid large-scale training with all classes and examples.  Our learned mid-level features are build on shape and color detectors estimated from discovered patches reflecting small highly discriminative structures in the queried images.  We evaluate our approach for fine-grained recognition on the CUB-2011 birds dataset and show that high recognition rates can be obtained by model combination.
          
        </div>
        </td>
        </table>
        </div>
        <div class='vspace'></div>
    
        <div class='paperblock' >
        <table>
	  
        <td width=150px>
	  
        
          
                <img width=90% class=teaserimg src="http://hera.inf-cv.uni-jena.de:6680/teaser/Simon14:PDD">
          
        
        </td>
        <td style='vertical-align:middle'>
        
 	      <span class=bibtitle>
          <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Simon14:PDD.pdf">Part Detector Discovery in Deep Convolutional Neural Networks</a>.</span>
          <br />
          <span class=bibauthor>Marcel Simon and Erik Rodner and Joachim Denzler.</span>
          <br />
          <span class=bibvenue>Asian Conference on Computer Vision (ACCV).</span>
          
          <span class=bibpages>162-177.</span>
          
          <span class=bibyear>2014.</span>
        
		
		
	
        <a href="http://hera.inf-cv.uni-jena.de:6680/bib/Simon14:PDD" onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img src="bibworldfiles/get-bib-source.png" alt="BibTeX" /></a>
        
        <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Simon14:PDD.pdf"><img src="bibworldfiles/pdf-document.png" alt="pdf" title="pdf"/></a>
        
        
        
        <a href="https://github.com/cvjena/PartDetectorDisovery"><img src="bibworldfiles/code-link.png" alt="code" title="code" target="_blank"/></a>
        
        
        
        
        <span class="abstractlink" onClick="abstractclick('Simon14:PDD');">more ...</span>
        <div class="bibabstract" id="Simon14:PDD">
          <br />
          <div class='vspace'></div>
          Abstract: Current fine-grained classification approaches often rely  on a robust localization of object parts to extract  localized feature representations suitable for discrimination.  However, part localization is a  challenging task due to the large variation of appearance and pose.  In this paper, we show how pre-trained convolutional neural networks  can be used for robust and efficient object part discovery and localization without the  necessity to actually train the network on the current dataset. Our approach called  part detector discovery  (PDD)  is based on analyzing the gradient maps of the network outputs and finding  activation centers spatially related to annotated semantic parts or bounding boxes.  This allows us not just to obtain excellent performance on the CUB200-2011 dataset,  but in contrast to previous approaches also to perform detection and bird classification jointly  without requiring a given bounding box annotation during testing and ground-truth parts during training.
          
        </div>
        </td>
        </table>
        </div>
        <div class='vspace'></div>
    
        <div class='paperblock' >
        <table>
	  
        <td width=150px>
	  
        
          
                <img width=90% class=teaserimg src="http://hera.inf-cv.uni-jena.de:6680/teaser/Simon14:PLE">
          
        
        </td>
        <td style='vertical-align:middle'>
        
 	      <span class=bibtitle>
          <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Simon14:PLE.pdf">Part Localization by Exploiting Deep Convolutional Networks</a>.</span>
          <br />
          <span class=bibauthor>Marcel Simon and Erik Rodner and Joachim Denzler.</span>
          <br />
          <span class=bibvenue>ECCV Workshop on Parts and Attributes (ECCV-WS).</span>
          
          <span class=bibyear>2014.</span>
        
		
		
	
        <a href="http://hera.inf-cv.uni-jena.de:6680/bib/Simon14:PLE" onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img src="bibworldfiles/get-bib-source.png" alt="BibTeX" /></a>
        
        <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Simon14:PLE.pdf"><img src="bibworldfiles/pdf-document.png" alt="pdf" title="pdf"/></a>
        
        
        <a href="https://filebox.ece.vt.edu/~parikh/PnA2014/"><img src="bibworldfiles/web-link.png" alt="www" title="www" target="_blank"/></a>
        
        
        
        
        
        </div>
        </td>
        </table>
        </div>
        <div class='vspace'></div>
    
        <div class='paperblock' >
        <table>
	  
        <td width=150px>
	  
        
          
                <img width=90% class=teaserimg src="http://hera.inf-cv.uni-jena.de:6680/teaser/Freytag14:BFF">
          
        
        </td>
        <td style='vertical-align:middle'>
        
 	      <span class=bibtitle>
          <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Freytag14:BFF.pdf">Birds of a Feather Flock Together - Local Learning of Mid-level Representations  for Fine-grained Recognition</a>.</span>
          <br />
          <span class=bibauthor>Alexander Freytag and Erik Rodner and Joachim Denzler.</span>
          <br />
          <span class=bibvenue>ECCV Workshop on Parts and Attributes (ECCV-WS).</span>
          
          <span class=bibyear>2014.</span>
        
		
		
	
        <a href="http://hera.inf-cv.uni-jena.de:6680/bib/Freytag14:BFF" onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img src="bibworldfiles/get-bib-source.png" alt="BibTeX" /></a>
        
        <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Freytag14:BFF.pdf"><img src="bibworldfiles/pdf-document.png" alt="pdf" title="pdf"/></a>
        
        
        <a href="https://filebox.ece.vt.edu/~parikh/PnA2014/"><img src="bibworldfiles/web-link.png" alt="www" title="www" target="_blank"/></a>
        
        
        <a href="https://github.com/cvjena/patchDiscovery"><img src="bibworldfiles/code-link.png" alt="code" title="code" target="_blank"/></a>
        
        
        <a href="http://hera.inf-cv.uni-jena.de:6680/presentation/Freytag14:BFF.pdf"><img src="bibworldfiles/presentation.png" alt="presentation" title="presentation" target="_blank"/></a>
        
        
        
        </div>
        </td>
        </table>
        </div>
        <div class='vspace'></div>
    
        <div class='paperblock' >
        <table>
	  
        <td width=150px>
	  
        
          
                <img width=90% class=teaserimg src="http://hera.inf-cv.uni-jena.de:6680/teaser/Goering14:NPT">
          
        
        </td>
        <td style='vertical-align:middle'>
        
 	      <span class=bibtitle>
          <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Goering14:NPT.pdf">Nonparametric Part Transfer for Fine-grained Recognition</a>.</span>
          <br />
          <span class=bibauthor>Christoph GÃ¶ring and Erik Rodner and Alexander Freytag and Joachim  Denzler.</span>
          <br />
          <span class=bibvenue>IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</span>
          
          <span class=bibpages>2489-2496.</span>
          
          <span class=bibyear>2014.</span>
        
		
		
	
        <a href="http://hera.inf-cv.uni-jena.de:6680/bib/Goering14:NPT" onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img src="bibworldfiles/get-bib-source.png" alt="BibTeX" /></a>
        
        <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Goering14:NPT.pdf"><img src="bibworldfiles/pdf-document.png" alt="pdf" title="pdf"/></a>
        
        
        <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Goring_Nonparametric_Part_Transfer_2014_CVPR_paper.pdf"><img src="bibworldfiles/web-link.png" alt="www" title="www" target="_blank"/></a>
        
        
        <a href="https://github.com/cvjena/finegrained-cvpr2014"><img src="bibworldfiles/code-link.png" alt="code" title="code" target="_blank"/></a>
        
        
        <a href="http://hera.inf-cv.uni-jena.de:6680/presentation/Goering14:NPT.pdf"><img src="bibworldfiles/presentation.png" alt="presentation" title="presentation" target="_blank"/></a>
        
        
        
        <span class="abstractlink" onClick="abstractclick('Goering14:NPT');">more ...</span>
        <div class="bibabstract" id="Goering14:NPT">
          <br />
          <div class='vspace'></div>
          Abstract: In the following paper, we present an approach for fine-grained recognition based on a new part detection method.  In particular, we propose a nonparametric label transfer technique which transfers part constellations from objects with similar global shapes.  The possibility for transferring part annotations to unseen images allows for coping with a high degree of pose and view variations in scenarios where  traditional detection models (such as deformable part models) fail.  Our approach is especially  valuable for fine-grained recognition scenarios where intraclass variations are extremely high, and  precisely localized features need to be extracted.  Furthermore, we show the importance of carefully designed visual extraction strategies, such as combination of complementary feature types and  iterative image segmentation, and the resulting impact on the recognition performance.  In experiments, our simple yet powerful approach achieves 35.9% and 57.8% accuracy on the CUB-2010 and 2011 bird datasets,  which is the current best performance for these benchmarks.
          
        </div>
        </td>
        </table>
        </div>
        <div class='vspace'></div>
    

    <h2>2013</h2>
    
        <div class='paperblock' >
        <table>
	  
        <td width=150px>
	  
        
          
                <img width=90% class=teaserimg src="http://hera.inf-cv.uni-jena.de:6680/teaser/Goering13:FGC">
          
        
        </td>
        <td style='vertical-align:middle'>
        
          <span class=bibtitle>
          <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Goering13:FGC.pdf">Fine-grained Categorization - Short Summary of our Entry for the  ImageNet Challenge 2012</a>.</span>
          <br />
          <span class=bibauthor>Christoph GÃ¶ring and Alexander Freytag and Erik Rodner and Joachim  Denzler.</span>
          <br />
          <span class=bibvenue>arXiv preprint arXiv:1310.4759.</span>
          
          
          <span class=bibyear>2013.</span>
        
		
		
	
        <a href="http://hera.inf-cv.uni-jena.de:6680/bib/Goering13:FGC" onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img src="bibworldfiles/get-bib-source.png" alt="BibTeX" /></a>
        
        <a href="http://hera.inf-cv.uni-jena.de:6680/pdf/Goering13:FGC.pdf"><img src="bibworldfiles/pdf-document.png" alt="pdf" title="pdf"/></a>
        
        
        <a href="http://arxiv.org/abs/1310.4759"><img src="bibworldfiles/web-link.png" alt="www" title="www" target="_blank"/></a>
        
        
        
        
        
        </div>
        </td>
        </table>
        </div>
        <div class='vspace'></div>
    

</div>